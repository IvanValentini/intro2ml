\chapter{Machine learning basics}

\section{Introduzione}
Il machine learning permette ai computer di acquisire conoscenza attraverso algoritmi che imparano e inferiscono dai dati.
Tale conoscenza viene rappresentata da un modello che viene poi utilizzato su dati futuri.

	\subsection{Processo di learning}
	Si individua un processo di learning:
	\begin{multicols}{2}
		\begin{itemize}
			\item Acquisizione di dati dal mondo reale attraverso sensori.
			\item Preprocessamento dei dati: eliminazione del rumore, estrazione delle features e normalizzazione.
			\item Riduzione di dimensionalit\`a attraverso selezione e proiezione di features.
			\item Learning del modello: classification, regression, clustering e description.
			\item Test del modello attraverso cross-validation e bootstrap.
			\item Analisi dei risultati.
		\end{itemize}
	\end{multicols}

\section{Dati}
I dati disponibili ad un algoritmo di machine learning sono tipicamente un insieme di esempi.
Questi esempi sono tipicamente rappresentati come un array di features, caratteristiche dei dati di interesse per lo studio in atto.

	\subsection{Training e test set}
	In particolare per questi algoritmi si assume sempre che il training e il test set siano distribuiti secondo variabili indipendenti e identicamente distribuite (\emph{i.i.d})
	La distribuzione $P_{data}$ \`e tipicamente sconosciuta ma si pu\`o campionare, attraverso un modello probabilistico di learning.
	In particolare la distribuzione di probabilit\`a di coppie di esempio e label viene detta data generating distribution e sia il training data che il test set sono generati basandosi su di essa.

\section{Task}
Si intende per task una rappresentazione del tipo di predizione che viene svolta per risolvere un problema su dei dati.
Viene identificata con un insieme di funzioni che possono potenzialmente risolverla.
In generale consiste di una funzione che assegna ogni input $x\in\mathcal{X}$ a un output $y\in\mathcal{Y}$:
$$f:\mathcal{X}\rightarrow\mathcal{Y}\qquad\mathcal{F}_{task}\subset\mathcal{Y^X}$$
La natura di $\mathcal{X},\mathcal{Y}, \mathcal{F}_{task}$ dipende dal tipo di task.

\section{Modello}
Un modello \`e un programma per risolvere un problema.
\`E cio\`e l'implementazione di una funzione $f\in\mathcal{F}_{task}$ che pu\`o essere computata.
Un insieme di modelli formano uno spazio di ipotesi:
$$\mathcal{H}\subset\mathcal{F}_{task}$$
L'algoritmo cerca una soluzione nello spazio di ipotesi.
Esistono diversi tipi di modello:
\begin{multicols}{2}
	\begin{itemize}
		\item Generativi e discriminativi.
		\item Parametrici e non parametrici.
	\end{itemize}
\end{multicols}

	\subsection{Target ideale}
	Il target ideale del modello \`e quello di minimizzare una funzione di errore (generalizzazione)
	$$E(f;P_{data})$$
	Questa funzione determina quanto bene una soluzione $f\in\mathcal{F}_{task}$ fitta dei dati.
	Guida pertanto la selezione della migliore soluzione in $\mathcal{F}_{task}$.
	Pertanto:
	$$f^*\in arg\min\limits_{f\in\mathcal{F}_{task}}E(f;P_{data})$$

	\subsection{Target feasible}
	Si deve restringere il focus sul trovare funzioni che possono essere implementate e valutate in maniera trattabile.
	Si definisce pertanto uno spazio di ipotesi del modello $\mathcal{H}\subset\mathcal{F}_{task}$ e si cerca la soluzione all'interno di quello spazio:
	$$f^*_{\mathcal{H}}\in arg\min\limits_{f\in\mathcal{H}} E(f;P_{data})$$
	Si noti come questa funzione non possa essere computata correttamente in quanto $P_{data}$ \`e sconosciuta.

	\subsection{Target attuale}
	Per trovare il target attuale si deve lavorare su un campione di dati o il training set
	$$\mathcal{D}_n=\{z_1,\dots,z_n\}$$
	Dove
	$$z_i=(x_i,y_i)\in\mathcal{X}\times\mathcal{Y}$$
	$$z_i\sim P_{data}$$
	Pertanto in:
	$$f^*_{\mathcal{H}}\in arg\min\limits_{f\in\mathcal{H}} E(f;P_{data})$$
	$E(f;P_{data})$ \`e il training error.

	\subsection{Funzione di errore}
	Le funzioni di generalizzazione e di training error possono essere scritte in termini di una pointwise loss $l(f;z)$ che misura l'errore che avviene a $f$ su un esempio di training $z$.
	$$E(f;P_{data})=\mathbb{E}_{z\sim P_{data}}[l(f;z)]$$
	$$E(f;\mathcal{D}_n)=\dfrac{1}{n}\sum\limits_{i=1}^nl(f;z_i)$$
	Si nota pertanto come l'algoritmo di learning risolve il problema di ottimizzazione con target:
	$$f^*_\mathcal{H}(\mathcal{D}_n)$$

	\subsection{Tipi di errore}
	\begin{multicols}{2}
		\begin{itemize}
			\item Underfitting il modello non fitta sui dati di training, avviene per mancanza di dati.
			\item Overfitting quando i training data sono rumorosi e il modello li fitta perfettamente, ma impara un modello che si adatta solo su di essi e non fitta dati dal mondo reale.
			\item Estimation error, indotto imparando da un campione di dati.
			\item Approximation error, indotto dallo spazio di ipotesi $\mathcal{H}$.
			\item Irreducible error a causa della variabilit\`a intrinseca.
		\end{itemize}
	\end{multicols}

	\subsection{Stimare l'errore di generalizzazione}
	L'errore di geenralizzazione pu\`o essere stimato utilizzando diversi insiemi di training, validation e test.
	Si usa il training set per fare training di un modello, quello di validazione per valutarlo e sistemare i suoi iperparametri e dopo di quello si sceglie il modello migliore che si misura attraverso le performance sul test set.

		\subsubsection{Migliorare la generalizzazione}
		La generalizzazione pu\`o essere migliorata:
		\begin{multicols}{2}
			\begin{itemize}
				\item Evitando di ottenere il minimo sul training error.
				\item Riducendo la capacit\`a del modello.
				\item Cambiando l'obiettivo con un termine di regolarizzazione.
				\item Iniettando rumore nell'algoritmo.
				\item Fermando l'algoritmo prima che converga.
				\item Aumentantdo la quantit\`a di dati.
				\item Aggiungendo pi\`u campioni di training.
				\item Aumentando il training set con trasformazioni.
				\item Combinando predizioni da pi\`u modelli decorrelati o ensembling.
			\end{itemize}
		\end{multicols}

			\paragraph{Regolarizzazione}
			Si intende per regolarizzazione la modifica della funzione di training error con un termine $\Omega(f)$ che penalizza soluzioni complesse:
			$$E_{reg}(f;\mathcal{D}_n)=E(f;\mathcal{D}_n)+\lambda_n\Omega(f)$$


\section{Tipi di learning}

	\subsection{Supervised learning}
	Nel supervised learning vengono dati in input a un modello o predittore un insieme di esempi che possiedono una label.
	Il modello poi impara a creare delle predizioni su un nuovo esempio.

		\subsubsection{Dati}
		Nel caso del supervised learning i dati creano una distribuzione:
		$$p_{data}\in\Delta(\mathcal{X}\times\mathcal{Y})$$

		\subsubsection{Classificazione}
		In un problema di classificazione si trova un insieme finito di label discrete.
		In particolare dato un training set $\mathcal{T} = \{(x_1, u_1),\dots(x_m, y_m)\}$, si deve imparare una funzione $f$ per predirre $y$ dato $x$.
		$f$ sar\`a pertanto:
		$$f:\mathbb{R}^d \rightarrow\{1, 2, \dots, k\}$$
		Dove $d$ \`e la dimensionalit\`a di $x$ e $k$ il numero di labels distinte.

			\paragraph{Task}
			Si deve pertanto trovare una funzione $f\in\mathcal{Y^X}$ che assegna ogni input $x\in\mathcal{X}$ a una label discreta.
			$$f(x)\in\mathcal{Y}=\{c_1,\dots,c_k\}$$

		\subsubsection{Regression}
		Un problema di regressione presenta un insieme di label continue.
		Dato un training set $\mathcal{T}=\{(x_1, y_1),\dots,(x_m,y_m)\}$, si deve imparare una funzione $f$ per predirre $y$ dato $x$.
		$f$ sar\`a pertanto:
		$$f:\mathbb{R}^d\rightarrow\mathbb{R}$$
		Dove $d$ \`e la dimensionalit\`a di $x$.

			\paragraph{Task}
			Si deve trovare una funzione $f(x)\in\mathcal{Y}$ che assegna ogni input a una label continua.

		\subsubsection{Ranking}
		Il ranking \`e un tipo particolare di classificazione in cui una label \`e un ranking.

	\subsection{Unsupervised learning}
	Nel unsupervised learning vengono dati in input a un modello o predittore un insieme di esempi senza label.
	Il modello impara a creare delle predizioni su un nuovo esempio.

		\subsubsection{Dati}
		Nel caso del supervised learning i dati creano una distribuzione:
		$$p_{data}\in\Delta(\mathcal{X})$$

		\subsubsection{Clustering}
		Nel clustering, data $\mathcal{T}=\{x_1, \dots, x_m\}$ si deve trovare la struttura nascosta che intercorre tra le $x$ o i clusters.

			\paragraph{Task}
			Si deve trovare una funzione $f\in\mathbb{N}^{\mathcal{X}}$ che assegna ogni input $x\in\mathcal{X}$ a un indice di cluster $f(x)\in\mathbb{N}$.
			Tutti i punti mappati sullo stesso indice formano un cluster.

		\subsubsection{Dimensionality reduction}
		Nella dimensionality reduction si tenta di ridurre il numero di variabili sotto considerazione ottenendo un insieme di variabili principali.

			\paragraph{Task}
			Si deve trovare una funzione $f\in\mathcal{Y}^\mathcal{X}$ che mappa ogni input di molte dimensioni $x\in\mathcal{X}$ a un output a dimensione minore $f(x)\in\mathcal{Y}$, dove $dim(\mathcal{Y})\ll dim(\mathcal{X})$

	\subsection{Reinforcement learning}
	Nel reinforcement learning un agente impara dall'ambiente interagendo con esso e ricevendo premi per lo svolgimento di azioni particolari.
	In particolare, data una sequenza di esempi o stati e una reward dopo il completamento di tale sequenza si impara a predirre l'azione da svolgere per uno stato o esempio individuale.
