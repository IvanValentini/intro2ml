\chapter{Modelli lineari}

\section{Introduzione}
Alcuni approcci del machine learning fanno delle forti assunzioni riguardo i dati.
Questo avviene in quanto se le assunzioni sono vere si possono raggiungere performance migliori.
In caso contrario l'approccio pu\`o fallire miseramente.
Altri approcci che non fanno molte assunzioni riguardo i dati invece permettono di imparare da dati pi\`u vari ma sono pi\`u proni a overfitting e richiedono pi\`u dati di training.

	\subsection{Bias}
	Il bias di un modello \`e quanto forte le assunzioni del modello sono.
	I classificatori a low-bias fanno delle assunzioni minime riguardo i dati come \emph{k-NN} (che assume unicamente che la vicinanza \`e correlata alla classe) e \emph{DT}.
	I classificatori a high-bias fanno assunzioni forti riguardo ai dati.

\section{Linear separability}
L'assunzione strong-bias dei modelli lineari \`e la linear separability, ovvero che in due dimensioni le classi si possano separare attraverso una linea, mentre in dimensioni maggiori da un hyperplane.
Un modello lineare \`e pertanto un modello che assume che i dati sono linearmente separabili.

	\subsection{Definire una linea}
	Ogni coppia di valori $(w_1,w_2)$ definisce una linea attraverso l'origine:
	$$0=w_1f_1+w_2f_2$$
	Si pu\`o inoltre vedere il vettore $\overrightarrow{w}=(w_1, w_2)$ come il vettore dei pesi perpendicolare alla linea.
	Per classificare i punti rispetto alla linea si considera il segno sostituendo i punti a $f_1$ e $f_2$.
	La positivit\`a o negativit\`a indica il lato della linea.
	Si pu\`o estendere l'equazione con:
	$$a=w_1f_1+w_2f_2$$
	In questo modo la linea interseca l'asse delle $y$ in $a$.

\section{Definizione di modello lineare}
Si definisce un modello lineare in uno spazio $n$ dimensionale, dove $n$ \`e il numero di features attraverso $n+1$ pesi.
$$0=b+\sum\limits_{i=1}^nw_if_i$$
In un modello lineare si classifica un nuovo esempio moltiplicandolo con il vettore dei pesi, aggiungendo il bias e controllando il segno del risultato.
Questo determina la classe dell'esempio.

	\subsection{Training}
	Il training di un modello lineare avviene online, ovvero a differenza del modo in batch in cui vengono dati i training data come $\{(x_i, y_i):1\le i\le n\}$, i data points arrivano uno alla volta.
	L'algoritmo allora riceve un esempio $x_i$ senza label, predice la classificazione di questo esempio e confronta la predizione con l'effettivo $y_i$.
	Infine aggiorna il proprio modello.

	\subsection{Perceptron}

		\subsubsection{Numero di iterazioni}
		Il numero di iterazioni del perceptron viene deciso in base alla convergenza.
		Inoltre pu\`o essere limitato in modo da ridurre l'overfitting.
		Si noti come in caso di dati non lineramente separabili la convergenza non avviene mai.

		\subsubsection{Ordine dei campioni}
		I campioni da considerare nel perceptron sono considerati in ordine casuale.
		In questo modo si produce un modello a low bias.

		\subsubsection{Linear separable sets}
		Le istanze di training sono lienarmente separabili se esiste un hyperplane che separa le due classi.

		\subsubsection{Algoritmo}
		\input{Pseudocodice/01_perceptron}

		\subsubsection{Calcolo della predizione}
		\input{Pseudocodice/02_perceptron_prediction}

\section{Perceptron e reti neurali}
Si pu\`o immaginare il perceptron come un neurone artificiale o una funzione parametrizzata non lineare con un valore di attivazione soglia e un range di output ristretto.
Le reti neurali sono reti di neuroni artificiali densamente connessi in modo da simulare la rete di neuroni del cervello.

	\subsection{Funzione di attivazione}
	Una funzione di attivazione pu\`o essere una soglia dura: se la somma di tutti gli input \`e maggiore di un valore allora il perceptron manda il segnale queste permettono di imparare solo modelli lineari.
	Funzioni di attivazione pi\`u interessanti sono le sigmoidi, tangenti iperboliche, ReLU o rectified linear unit o leaky ReLU.

	\subsection{Storia del perceptron}
	Il perceptron nasce nel $1958$ da parte di Rosemblatt che lo crea con una soglia dura.
	Questo gli impedisce di imparare modelli non lineari come lo \emph{xor}.
	Viene superato nel $1986$ attraverso perceptrons multi layers e backpropagation e utilizzando una soglia meno dura.
