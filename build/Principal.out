\BOOKMARK [0][-]{chapter.1}{Introduzione}{}% 1
\BOOKMARK [1][-]{section.1.1}{Definizioni}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Processo}{chapter.1}% 3
\BOOKMARK [2][-]{subsection.1.2.1}{Il processo di apprendimento}{section.1.2}% 4
\BOOKMARK [1][-]{section.1.3}{Modello}{chapter.1}% 5
\BOOKMARK [1][-]{section.1.4}{Deep learning}{chapter.1}% 6
\BOOKMARK [0][-]{chapter.2}{Machine learning basics}{}% 7
\BOOKMARK [1][-]{section.2.1}{Introduzione}{chapter.2}% 8
\BOOKMARK [2][-]{subsection.2.1.1}{Processo di learning}{section.2.1}% 9
\BOOKMARK [1][-]{section.2.2}{Dati}{chapter.2}% 10
\BOOKMARK [2][-]{subsection.2.2.1}{Training e test set}{section.2.2}% 11
\BOOKMARK [1][-]{section.2.3}{Task}{chapter.2}% 12
\BOOKMARK [1][-]{section.2.4}{Modello}{chapter.2}% 13
\BOOKMARK [2][-]{subsection.2.4.1}{Target ideale}{section.2.4}% 14
\BOOKMARK [2][-]{subsection.2.4.2}{Target feasible}{section.2.4}% 15
\BOOKMARK [2][-]{subsection.2.4.3}{Target attuale}{section.2.4}% 16
\BOOKMARK [2][-]{subsection.2.4.4}{Funzione di errore}{section.2.4}% 17
\BOOKMARK [2][-]{subsection.2.4.5}{Tipi di errore}{section.2.4}% 18
\BOOKMARK [2][-]{subsection.2.4.6}{Stimare l'errore di generalizzazione}{section.2.4}% 19
\BOOKMARK [1][-]{section.2.5}{Tipi di learning}{chapter.2}% 20
\BOOKMARK [2][-]{subsection.2.5.1}{Supervised learning}{section.2.5}% 21
\BOOKMARK [2][-]{subsection.2.5.2}{Unsupervised learning}{section.2.5}% 22
\BOOKMARK [2][-]{subsection.2.5.3}{Reinforcement learning}{section.2.5}% 23
\BOOKMARK [0][-]{chapter.3}{KNN}{}% 24
\BOOKMARK [1][-]{section.3.1}{Introduzione}{chapter.3}% 25
\BOOKMARK [1][-]{section.3.2}{Misurare la distanza}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.3}{Decision boundaries}{chapter.3}% 27
\BOOKMARK [1][-]{section.3.4}{Il ruolo di K}{chapter.3}% 28
\BOOKMARK [2][-]{subsection.3.4.1}{Underfitting}{section.3.4}% 29
\BOOKMARK [2][-]{subsection.3.4.2}{Overfitting}{section.3.4}% 30
\BOOKMARK [1][-]{section.3.5}{Scelta di K}{chapter.3}% 31
\BOOKMARK [1][-]{section.3.6}{Variazioni di K}{chapter.3}% 32
\BOOKMARK [2][-]{subsection.3.6.1}{K-NN pesata}{section.3.6}% 33
\BOOKMARK [0][-]{chapter.4}{Modelli lineari}{}% 34
\BOOKMARK [1][-]{section.4.1}{Introduzione}{chapter.4}% 35
\BOOKMARK [2][-]{subsection.4.1.1}{Bias}{section.4.1}% 36
\BOOKMARK [1][-]{section.4.2}{Linear separability}{chapter.4}% 37
\BOOKMARK [2][-]{subsection.4.2.1}{Definire una linea}{section.4.2}% 38
\BOOKMARK [1][-]{section.4.3}{Definizione di modello lineare}{chapter.4}% 39
\BOOKMARK [2][-]{subsection.4.3.1}{Training}{section.4.3}% 40
\BOOKMARK [2][-]{subsection.4.3.2}{Perceptron}{section.4.3}% 41
\BOOKMARK [1][-]{section.4.4}{Perceptron e reti neurali}{chapter.4}% 42
\BOOKMARK [2][-]{subsection.4.4.1}{Funzione di attivazione}{section.4.4}% 43
\BOOKMARK [2][-]{subsection.4.4.2}{Storia del perceptron}{section.4.4}% 44
\BOOKMARK [0][-]{chapter.5}{Decision Trees}{}% 45
\BOOKMARK [1][-]{section.5.1}{Struttura}{chapter.5}% 46
\BOOKMARK [1][-]{section.5.2}{Funzionamento}{chapter.5}% 47
\BOOKMARK [2][-]{subsection.5.2.1}{Inferenza}{section.5.2}% 48
\BOOKMARK [1][-]{section.5.3}{Decision trees learning algorithm}{chapter.5}% 49
\BOOKMARK [2][-]{subsection.5.3.1}{Crescere una foglia}{section.5.3}% 50
\BOOKMARK [2][-]{subsection.5.3.2}{Crescere un nodo}{section.5.3}% 51
\BOOKMARK [2][-]{subsection.5.3.3}{Algoritmo}{section.5.3}% 52
\BOOKMARK [2][-]{subsection.5.3.4}{Split selection}{section.5.3}% 53
\BOOKMARK [2][-]{subsection.5.3.5}{Predizione delle foglie}{section.5.3}% 54
\BOOKMARK [1][-]{section.5.4}{Misure di impurit\340 per la classificazione}{chapter.5}% 55
\BOOKMARK [1][-]{section.5.5}{Misure di impurit\340 per la regressione}{chapter.5}% 56
\BOOKMARK [1][-]{section.5.6}{Data features e attributi}{chapter.5}% 57
\BOOKMARK [1][-]{section.5.7}{Funzioni di split o routing}{chapter.5}% 58
\BOOKMARK [2][-]{subsection.5.7.1}{Features discrete e nominali}{section.5.7}% 59
\BOOKMARK [2][-]{subsection.5.7.2}{Features ordinali}{section.5.7}% 60
\BOOKMARK [2][-]{subsection.5.7.3}{Obliquo}{section.5.7}% 61
\BOOKMARK [1][-]{section.5.8}{Decision trees e overfitting}{chapter.5}% 62
\BOOKMARK [1][-]{section.5.9}{Random forest}{chapter.5}% 63
\BOOKMARK [1][-]{section.5.10}{Confronto con KNN}{chapter.5}% 64
\BOOKMARK [0][-]{chapter.6}{Multi class classification}{}% 65
\BOOKMARK [1][-]{section.6.1}{Introduzione}{chapter.6}% 66
\BOOKMARK [2][-]{subsection.6.1.1}{Classificazione binaria}{section.6.1}% 67
\BOOKMARK [2][-]{subsection.6.1.2}{Classificazione multi classe}{section.6.1}% 68
\BOOKMARK [2][-]{subsection.6.1.3}{Approccio black box alla multi class classification}{section.6.1}% 69
\BOOKMARK [1][-]{section.6.2}{One versus all OVA}{chapter.6}% 70
\BOOKMARK [2][-]{subsection.6.2.1}{Ambiguit\340}{section.6.2}% 71
\BOOKMARK [2][-]{subsection.6.2.2}{Algoritmi}{section.6.2}% 72
\BOOKMARK [1][-]{section.6.3}{All versus all AVA}{chapter.6}% 73
\BOOKMARK [2][-]{subsection.6.3.1}{AVA training}{section.6.3}% 74
\BOOKMARK [2][-]{subsection.6.3.2}{AVA classification}{section.6.3}% 75
\BOOKMARK [2][-]{subsection.6.3.3}{Algoritmi}{section.6.3}% 76
\BOOKMARK [1][-]{section.6.4}{Confronto tra OVA e AVA}{chapter.6}% 77
\BOOKMARK [2][-]{subsection.6.4.1}{Tempo di training}{section.6.4}% 78
\BOOKMARK [2][-]{subsection.6.4.2}{Tempo di test}{section.6.4}% 79
\BOOKMARK [2][-]{subsection.6.4.3}{Errori}{section.6.4}% 80
\BOOKMARK [1][-]{section.6.5}{Riassunto}{chapter.6}% 81
\BOOKMARK [1][-]{section.6.6}{Multiclass evaluation}{chapter.6}% 82
\BOOKMARK [2][-]{subsection.6.6.1}{Microaveraging}{section.6.6}% 83
\BOOKMARK [2][-]{subsection.6.6.2}{Macroaveraging}{section.6.6}% 84
\BOOKMARK [2][-]{subsection.6.6.3}{Confusion matrix}{section.6.6}% 85
\BOOKMARK [0][-]{chapter.7}{Ranking}{}% 86
\BOOKMARK [1][-]{section.7.1}{Classificazione multiclasse e multilabel}{chapter.7}% 87
\BOOKMARK [1][-]{section.7.2}{Problema del ranking}{chapter.7}% 88
\BOOKMARK [2][-]{subsection.7.2.1}{Preference function}{section.7.2}% 89
\BOOKMARK [1][-]{section.7.3}{Utilizzo del ranking e della preference function}{chapter.7}% 90
\BOOKMARK [1][-]{section.7.4}{Ordinamento e -ranking}{chapter.7}% 91
\BOOKMARK [0][-]{chapter.8}{Gradient descent}{}% 92
\BOOKMARK [1][-]{section.8.1}{Model based machine learning}{chapter.8}% 93
\BOOKMARK [2][-]{subsection.8.1.1}{Modelli lineari}{section.8.1}% 94
\BOOKMARK [1][-]{section.8.2}{Loss functions}{chapter.8}% 95
\BOOKMARK [2][-]{subsection.8.2.1}{Loss 0/1}{section.8.2}% 96
\BOOKMARK [2][-]{subsection.8.2.2}{Funzioni convesse}{section.8.2}% 97
\BOOKMARK [2][-]{subsection.8.2.3}{Surrogate loss function}{section.8.2}% 98
\BOOKMARK [1][-]{section.8.3}{Gradient descent}{chapter.8}% 99
\BOOKMARK [2][-]{subsection.8.3.1}{Spostamento in direzione della minimizzazione dell'errore}{section.8.3}% 100
\BOOKMARK [2][-]{subsection.8.3.2}{Learning algorithm del perceptron}{section.8.3}% 101
\BOOKMARK [2][-]{subsection.8.3.3}{Costante c}{section.8.3}% 102
\BOOKMARK [2][-]{subsection.8.3.4}{Gradiente}{section.8.3}% 103
\BOOKMARK [0][-]{chapter.9}{Regularization}{}% 104
\BOOKMARK [1][-]{section.9.1}{Introduzione}{chapter.9}% 105
\BOOKMARK [1][-]{section.9.2}{Regolarizzatori}{chapter.9}% 106
\BOOKMARK [2][-]{subsection.9.2.1}{Regolarizzatori comuni}{section.9.2}% 107
\BOOKMARK [1][-]{section.9.3}{Gradient descent e regolarizzazione}{chapter.9}% 108
\BOOKMARK [1][-]{section.9.4}{Regolarizzazione con le p-norms}{chapter.9}% 109
\BOOKMARK [2][-]{subsection.9.4.1}{L1}{section.9.4}% 110
\BOOKMARK [2][-]{subsection.9.4.2}{L2}{section.9.4}% 111
\BOOKMARK [2][-]{subsection.9.4.3}{Lp}{section.9.4}% 112
\BOOKMARK [1][-]{section.9.5}{Metodi di machine learning con regolarizzazione}{chapter.9}% 113
\BOOKMARK [0][-]{chapter.10}{Support vector machines}{}% 114
\BOOKMARK [1][-]{section.10.1}{Introduzione}{chapter.10}% 115
\BOOKMARK [2][-]{subsection.10.1.1}{Considerazioni su perceptron e gradient descent}{section.10.1}% 116
\BOOKMARK [2][-]{subsection.10.1.2}{Idea delle support vector machines}{section.10.1}% 117
\BOOKMARK [1][-]{section.10.2}{Margini}{chapter.10}% 118
\BOOKMARK [2][-]{subsection.10.2.1}{Support vectors}{section.10.2}% 119
\BOOKMARK [2][-]{subsection.10.2.2}{Calcolare il margine}{section.10.2}% 120
\BOOKMARK [1][-]{section.10.3}{Problema di ottimizzazione}{chapter.10}% 121
\BOOKMARK [2][-]{subsection.10.3.1}{Massimizzare il margine}{section.10.3}% 122
\BOOKMARK [1][-]{section.10.4}{Soft margin classification}{chapter.10}% 123
\BOOKMARK [2][-]{subsection.10.4.1}{Risolvere il problema delle SVM}{section.10.4}% 124
\BOOKMARK [1][-]{section.10.5}{Data non lineramente separabile}{chapter.10}% 125
\BOOKMARK [2][-]{subsection.10.5.1}{Soft margin classifier}{section.10.5}% 126
\BOOKMARK [2][-]{subsection.10.5.2}{Identificare i support vector}{section.10.5}% 127
\BOOKMARK [2][-]{subsection.10.5.3}{Utilizzo di SVN in maniera non lineare}{section.10.5}% 128
\BOOKMARK [0][-]{chapter.11}{Neural Networks}{}% 129
\BOOKMARK [1][-]{section.11.1}{Introduzione}{chapter.11}% 130
\BOOKMARK [1][-]{section.11.2}{Il perceptron multilayer}{chapter.11}% 131
\BOOKMARK [2][-]{subsection.11.2.1}{Feed forward NN}{section.11.2}% 132
\BOOKMARK [1][-]{section.11.3}{Second AI winter}{chapter.11}% 133
\BOOKMARK [1][-]{section.11.4}{Feed Forward Networks}{chapter.11}% 134
\BOOKMARK [2][-]{subsection.11.4.1}{Funzione di costo}{section.11.4}% 135
\BOOKMARK [2][-]{subsection.11.4.2}{L'architettura}{section.11.4}% 136
\BOOKMARK [2][-]{subsection.11.4.3}{Backpropagation}{section.11.4}% 137
\BOOKMARK [2][-]{subsection.11.4.4}{Scelta di un ottimizzatore}{section.11.4}% 138
\BOOKMARK [1][-]{section.11.5}{Convolutional Neural Netowrks \(CNN\)}{chapter.11}% 139
\BOOKMARK [2][-]{subsection.11.5.1}{Convolution}{section.11.5}% 140
\BOOKMARK [1][-]{section.11.6}{Convolutional Neural Netowrks \(CNN\)}{chapter.11}% 141
\BOOKMARK [2][-]{subsection.11.6.1}{Convolution}{section.11.6}% 142
\BOOKMARK [2][-]{subsection.11.6.2}{Definizione di una CNN}{section.11.6}% 143
\BOOKMARK [2][-]{subsection.11.6.3}{Operazione di convolution}{section.11.6}% 144
\BOOKMARK [2][-]{subsection.11.6.4}{Non linearity}{section.11.6}% 145
\BOOKMARK [2][-]{subsection.11.6.5}{Pooling}{section.11.6}% 146
\BOOKMARK [0][-]{chapter.12}{Reinforcement learning}{}% 147
\BOOKMARK [1][-]{section.12.1}{Introduzione}{chapter.12}% 148
\BOOKMARK [2][-]{subsection.12.1.1}{Policy}{section.12.1}% 149
\BOOKMARK [1][-]{section.12.2}{Markov decision process \(MDP\)}{chapter.12}% 150
\BOOKMARK [2][-]{subsection.12.2.1}{Componenti}{section.12.2}% 151
\BOOKMARK [2][-]{subsection.12.2.2}{Ambienti stocastici}{section.12.2}% 152
\BOOKMARK [2][-]{subsection.12.2.3}{MDP loop}{section.12.2}% 153
\BOOKMARK [2][-]{subsection.12.2.4}{Policy}{section.12.2}% 154
\BOOKMARK [1][-]{section.12.3}{Confronto tra reinforcement learning e supervised learning}{chapter.12}% 155
\BOOKMARK [2][-]{subsection.12.3.1}{Supervised learning loop}{section.12.3}% 156
\BOOKMARK [2][-]{subsection.12.3.2}{Reinforcement learning loop}{section.12.3}% 157
\BOOKMARK [2][-]{subsection.12.3.3}{Differenze fondamentali}{section.12.3}% 158
\BOOKMARK [1][-]{section.12.4}{Metodi di reinforcement learning}{chapter.12}% 159
\BOOKMARK [2][-]{subsection.12.4.1}{Value based methods}{section.12.4}% 160
\BOOKMARK [2][-]{subsection.12.4.2}{Policy gradient methods PGM}{section.12.4}% 161
\BOOKMARK [0][-]{chapter.13}{Unsupervised Learning}{}% 162
\BOOKMARK [0][-]{chapter.14}{Generative Models}{}% 163
