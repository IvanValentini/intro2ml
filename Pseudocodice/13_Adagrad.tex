\begin{algorithm}[H]
\DontPrintSemicolon
\SetKwComment{comment}{$\%$}{}
\SetKw{Int}{int}
\SetKw{To}{to}
\SetKw{IsNot}{is not}
\SetKw{Not}{not}
\SetKw{Return}{return}
\SetKw{Require}{return}
\SetKwData{Item}{item}
\SetKwFunction{Min}{min}
\SetKwFunction{GradientDescent}{AdaGrad}

\caption{\protect\GradientDescent}
	\Require : Learning rate $\varepsilon_k$\;
	\Require : Initial Parameter $\theta,\delta$\;
	r = 0\;
	\While{stopping criteria not met}{
		\comment{Compute gradient estimate over sample example ($x^{(i)}, y^{(i)}$) from training set}
		$\hat{g} = +\nabla_\theta\sum_i L(f(x^{(i)};\theta),y^{(i)})$\;
		\comment{Compute velocity update}
		r = r + $f\circ \hat{g}$
		\comment{Compute update}
		$\Delta\theta = -\frac{\varepsilon_k}{\delta+\sqrt{r}}\circ i\hat{g}$\;
		$\theta = \theta +\Delta\theta$\;
	}
\end{algorithm}
